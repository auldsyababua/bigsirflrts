# Story 1.6: [DEFERRED] Redis Queue Configuration

## ⚠️ DEFERRED - NOT NEEDED FOR CURRENT SCALE

**Status:** DEFERRED until scale exceeds 50+ users
**Decision Date:** 2025-09-15
**Architecture Decision:** [ADR-001: Single-Instance vs Queue Mode](/docs/architecture/adr-001-n8n-deployment-mode.md)

### Why This Was Deferred

After QA review and scale clarification (10 users, not 100+), we determined that n8n single-instance mode is sufficient for current and foreseeable needs. Queue mode with Redis provides 25-50x our current capacity requirements and adds unnecessary complexity.

**Current Solution:** Single-instance n8n deployment handles 100+ webhooks/hour easily with 2GB RAM and 1 CPU core.

**This story will be activated when:**
- User count exceeds 50 active users
- Webhook volume exceeds 500/hour consistently
- Execution times regularly exceed 30 seconds
- Memory usage consistently >80%

For current deployment, use: `/infrastructure/docker/docker-compose.single.yml`
For future queue mode reference: `/infrastructure/docker/docker-compose.yml`

---

## Original Overview

Set up Redis with BullMQ for job queue management, handling asynchronous operations and preventing duplicate task processing.

## Context

- **Epic**: Epic 1 - Infrastructure & Core Systems
- **Priority**: ~~P0 (Critical for MVP)~~ → P3 (Future scaling)
- **Dependencies**:
  - Story 1.1 (Supabase project setup) - COMPLETED
  - Story 1.2 (Redis instance setup) - COMPLETED
- **Blocks**: Story 2.1, 2.2, 3.2 (All async operations)

## Technical Requirements

### Redis Connection Configuration

```typescript
// Environment variables (Supabase Edge Functions)
interface RedisConfig {
  REDIS_HOST: string;        // Redis hostname/IP
  REDIS_PORT: number;        // Default: 6379
  REDIS_PASSWORD?: string;   // Optional for secured instances
  REDIS_DB?: number;         // Default: 0
  REDIS_TLS?: boolean;       // Use TLS for production
  REDIS_MAX_RETRIES?: number; // Default: 3
}

// BullMQ connection setup
import { Queue, Worker, QueueEvents } from 'bullmq';
import IORedis from 'ioredis';

const connection = new IORedis({
  host: process.env.REDIS_HOST,
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD,
  db: parseInt(process.env.REDIS_DB || '0'),
  maxRetriesPerRequest: 3,
  enableReadyCheck: true,
  retryStrategy: (times: number) => {
    const delay = Math.min(times * 50, 2000);
    return delay;
  }
});
```

### Queue Definitions

#### 1. Primary Queues

```typescript
// Queue names follow pattern: flrts:{feature}:{operation}
enum QueueNames {
  // Task management
  TASK_CREATE = 'flrts:tasks:create',
  TASK_UPDATE = 'flrts:tasks:update',
  TASK_SYNC = 'flrts:tasks:sync',

  // Reminder processing
  REMINDER_SCHEDULE = 'flrts:reminders:schedule',
  REMINDER_SEND = 'flrts:reminders:send',

  // Telegram operations
  TELEGRAM_OUTBOUND = 'flrts:telegram:outbound',
  TELEGRAM_COMMAND = 'flrts:telegram:command',

  // OpenProject sync
  OPENPROJECT_SYNC = 'flrts:openproject:sync',
  OPENPROJECT_WEBHOOK = 'flrts:openproject:webhook'
}

// Queue configuration with BullMQ
const defaultQueueOptions = {
  connection,
  defaultJobOptions: {
    removeOnComplete: {
      age: 3600,    // Keep completed jobs for 1 hour
      count: 100    // Keep max 100 completed jobs
    },
    removeOnFail: {
      age: 86400,   // Keep failed jobs for 24 hours
      count: 500    // Keep max 500 failed jobs
    },
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  }
};
```

#### 2. Queue Factory Pattern

```typescript
import { Queue, QueueOptions } from 'bullmq';

class QueueFactory {
  private static queues: Map<string, Queue> = new Map();

  static getQueue(name: QueueNames, options?: Partial<QueueOptions>): Queue {
    if (!this.queues.has(name)) {
      const queue = new Queue(name, {
        ...defaultQueueOptions,
        ...options
      });
      this.queues.set(name, queue);
    }
    return this.queues.get(name)!;
  }

  static async closeAll(): Promise<void> {
    const promises = Array.from(this.queues.values()).map(q => q.close());
    await Promise.all(promises);
    this.queues.clear();
  }
}
```

### Job Processing with Workers

#### 1. Worker Configuration

```typescript
import { Worker, Job, WorkerOptions } from 'bullmq';

const defaultWorkerOptions: WorkerOptions = {
  connection,
  concurrency: 10,  // Process 10 jobs in parallel
  limiter: {
    max: 100,       // Max 100 jobs
    duration: 60000 // Per minute
  },
  lockDuration: 30000, // Job lock for 30 seconds
  stalledInterval: 30000,
  maxStalledCount: 2
};

// Type-safe job processor
interface JobProcessor<T = any, R = any> {
  name: string;
  process: (job: Job<T>) => Promise<R>;
  onCompleted?: (job: Job<T>, result: R) => Promise<void>;
  onFailed?: (job: Job<T>, error: Error) => Promise<void>;
}
```

#### 2. Task Creation Worker Example

```typescript
const taskCreateProcessor: JobProcessor<TaskCreateData, TaskResult> = {
  name: QueueNames.TASK_CREATE,

  async process(job: Job<TaskCreateData>) {
    const { userId, title, description, dueDate } = job.data;

    // Idempotency check using job.id
    const existingTask = await checkExistingTask(job.id);
    if (existingTask) {
      return existingTask; // Skip duplicate processing
    }

    // Call n8n workflow to create task in OpenProject
    const response = await fetch(`${N8N_WEBHOOK_URL}/openproject-api`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        operation: 'create_work_package',
        data: { title, description, dueDate }
      })
    });

    if (!response.ok) {
      throw new Error(`OpenProject API failed: ${response.statusText}`);
    }

    const task = await response.json();

    // Store job.id to prevent reprocessing
    await storeProcessedJob(job.id, task.id);

    return task;
  },

  async onCompleted(job, result) {
    // Send confirmation to user via Telegram
    await notifyUser(job.data.userId, `Task created: ${result.subject}`);
  },

  async onFailed(job, error) {
    // Log error and notify user
    console.error(`Task creation failed for job ${job.id}:`, error);
    await notifyUser(job.data.userId, `Failed to create task: ${error.message}`);
  }
};

// Create worker
const taskWorker = new Worker(
  taskCreateProcessor.name,
  taskCreateProcessor.process,
  defaultWorkerOptions
);

taskWorker.on('completed', taskCreateProcessor.onCompleted);
taskWorker.on('failed', taskCreateProcessor.onFailed);
```

### Duplicate Prevention Strategies

#### 1. Job Deduplication

```typescript
interface DeduplicationOptions {
  deduplicationId?: string;  // Custom ID for deduplication
  deduplicationTTL?: number; // TTL in seconds
}

async function addJobWithDedup<T>(
  queue: Queue,
  name: string,
  data: T,
  options: DeduplicationOptions = {}
): Promise<Job<T> | null> {
  const dedupId = options.deduplicationId || generateDedupId(data);
  const dedupKey = `dedup:${queue.name}:${dedupId}`;

  // Use Redis SET NX for atomic check-and-set
  const wasSet = await connection.set(
    dedupKey,
    '1',
    'NX',
    'EX',
    options.deduplicationTTL || 3600
  );

  if (!wasSet) {
    console.log(`Job already exists with dedup ID: ${dedupId}`);
    return null;
  }

  try {
    const job = await queue.add(name, data, {
      jobId: dedupId // Use dedup ID as job ID
    });
    return job;
  } catch (error) {
    // Rollback dedup key on failure
    await connection.del(dedupKey);
    throw error;
  }
}

function generateDedupId(data: any): string {
  // Generate deterministic ID from data
  const crypto = require('crypto');
  const hash = crypto.createHash('sha256');
  hash.update(JSON.stringify(data));
  return hash.digest('hex').substring(0, 16);
}
```

#### 2. Rate Limiting Per User

```typescript
const userRateLimiter = {
  async checkLimit(userId: string, operation: string): Promise<boolean> {
    const key = `ratelimit:${userId}:${operation}`;
    const limit = 10; // 10 operations
    const window = 60; // per minute

    const current = await connection.incr(key);

    if (current === 1) {
      await connection.expire(key, window);
    }

    return current <= limit;
  }
};

// Usage in job processor
async function processWithRateLimit(job: Job) {
  const canProceed = await userRateLimiter.checkLimit(
    job.data.userId,
    job.name
  );

  if (!canProceed) {
    throw new Error('Rate limit exceeded');
  }

  // Continue processing...
}
```

### Queue Monitoring & Events

#### 1. Queue Events Setup

```typescript
import { QueueEvents } from 'bullmq';

const queueEvents = new QueueEvents(QueueNames.TASK_CREATE, { connection });

queueEvents.on('completed', ({ jobId, returnvalue }) => {
  console.log(`Job ${jobId} completed with result:`, returnvalue);
});

queueEvents.on('failed', ({ jobId, failedReason }) => {
  console.error(`Job ${jobId} failed:`, failedReason);
  // Send to monitoring service
});

queueEvents.on('stalled', ({ jobId }) => {
  console.warn(`Job ${jobId} stalled and will be retried`);
});

// Health check
async function checkQueueHealth(queueName: QueueNames) {
  const queue = QueueFactory.getQueue(queueName);
  const counts = await queue.getJobCounts();

  return {
    waiting: counts.waiting,
    active: counts.active,
    completed: counts.completed,
    failed: counts.failed,
    delayed: counts.delayed,
    isPaused: await queue.isPaused()
  };
}
```

#### 2. Metrics Collection

```typescript
interface QueueMetrics {
  processed: number;
  failed: number;
  avgProcessingTime: number;
  p95ProcessingTime: number;
}

class MetricsCollector {
  private metrics: Map<string, number[]> = new Map();

  recordJobDuration(queueName: string, duration: number) {
    if (!this.metrics.has(queueName)) {
      this.metrics.set(queueName, []);
    }
    this.metrics.get(queueName)!.push(duration);
  }

  getMetrics(queueName: string): QueueMetrics {
    const durations = this.metrics.get(queueName) || [];
    durations.sort((a, b) => a - b);

    return {
      processed: durations.length,
      failed: 0, // Track separately
      avgProcessingTime: durations.reduce((a, b) => a + b, 0) / durations.length,
      p95ProcessingTime: durations[Math.floor(durations.length * 0.95)] || 0
    };
  }
}
```

### Error Handling & Recovery

```typescript
// Dead letter queue for failed jobs
const deadLetterQueue = new Queue('flrts:dead-letter', defaultQueueOptions);

// Move failed jobs to DLQ after max attempts
taskWorker.on('failed', async (job, error) => {
  if (job.attemptsMade >= job.opts.attempts!) {
    await deadLetterQueue.add('failed-job', {
      originalQueue: job.queueName,
      jobData: job.data,
      error: error.message,
      failedAt: new Date().toISOString()
    });
  }
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  console.log('Shutting down workers...');
  await taskWorker.close();
  await QueueFactory.closeAll();
  await connection.quit();
  process.exit(0);
});
```

## Implementation Checklist

### Phase 1: Basic Setup

- [ ] Install Redis (Docker or managed service)
- [ ] Install BullMQ and ioredis packages
- [ ] Configure Redis connection with retry logic
- [ ] Create queue factory and worker base classes

### Phase 2: Core Queues

- [ ] Implement task creation queue and worker
- [ ] Implement reminder scheduling queue
- [ ] Set up Telegram command queue
- [ ] Configure OpenProject sync queue

### Phase 3: Advanced Features

- [ ] Add job deduplication mechanism
- [ ] Implement user rate limiting
- [ ] Set up dead letter queue
- [ ] Add queue monitoring and metrics

### Phase 4: Production Readiness

- [ ] Configure Redis persistence (AOF + RDB)
- [ ] Set up Redis Sentinel for HA
- [ ] Implement graceful shutdown
- [ ] Add health check endpoints

## Testing Requirements

```typescript
// Test helper for queue testing
import { Queue } from 'bullmq';
import { createSandbox } from 'sinon';

describe('Queue Processing', () => {
  let queue: Queue;
  let sandbox: any;

  beforeEach(() => {
    sandbox = createSandbox();
    queue = new Queue('test-queue', {
      connection: {
        host: 'localhost',
        port: 6379,
        db: 1 // Use separate DB for tests
      }
    });
  });

  afterEach(async () => {
    await queue.obliterate({ force: true });
    await queue.close();
    sandbox.restore();
  });

  it('should prevent duplicate job processing', async () => {
    const jobData = { userId: '123', task: 'test' };
    const dedupId = 'test-dedup-123';

    const job1 = await addJobWithDedup(queue, 'test', jobData, {
      deduplicationId: dedupId
    });

    const job2 = await addJobWithDedup(queue, 'test', jobData, {
      deduplicationId: dedupId
    });

    expect(job1).toBeDefined();
    expect(job2).toBeNull();
  });
});
```

## Performance Specifications

- Queue throughput: 1000+ jobs/second
- Job processing latency: < 100ms for simple operations
- Redis memory usage: ~1KB per job
- Connection pool size: 10-50 connections
- Worker concurrency: 10-100 based on job complexity

## Security Requirements

- Use TLS for Redis connections in production
- Implement job data encryption for sensitive information
- Sanitize all job data before processing
- Use separate Redis databases for different environments
- Implement RBAC for queue management operations

## Developer Resources

### Essential Documentation

```bash
# BullMQ documentation
mcp__ref__ref_search_documentation "BullMQ TypeScript queue worker patterns"

# Redis best practices
mcp__ref__ref_search_documentation "Redis queue patterns deduplication"

# Connection pooling
mcp__ref__ref_search_documentation "ioredis connection pool TypeScript"
```

### Debugging Commands

```bash
# Monitor Redis operations
redis-cli MONITOR

# Check queue status
redis-cli LLEN bull:flrts:tasks:create:wait

# Clear all queues (DANGER - dev only)
redis-cli FLUSHDB

# Check Redis memory usage
redis-cli INFO memory
```

## Acceptance Criteria

1. ✅ All queues process jobs successfully with retry logic
2. ✅ Duplicate jobs are detected and skipped
3. ✅ Failed jobs move to dead letter queue after max attempts
4. ✅ Queue metrics are collected and accessible
5. ✅ Graceful shutdown completes all active jobs
6. ✅ Rate limiting prevents user abuse

## Notes for Developers

- Always use typed job data interfaces for type safety
- Implement idempotency at the job processor level
- Use job.id for deduplication, not job data comparison
- Monitor Redis memory usage - implement job expiration
- Test queue behavior under high load (1000+ jobs)
- Use BullMQ Pro for enhanced features in production
